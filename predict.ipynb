{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4c0b39005bb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Test image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'train'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Predicting the output of the test image (same as training image). The steps here are largely analogous to the ones\n",
    "in 'train.py' and could in future iterations of this work be put into a reusable function (one could also just use\n",
    "'rgb_batch' in this special case of train and test data being the same)\n",
    "'''\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from train import *\n",
    "\n",
    "# Test image\n",
    "test_image = Image.open(\"rgb.png\")\n",
    "\n",
    "# Now, the same per-processing steps have to be taken\n",
    "\n",
    "test_array = np.array(test_image).reshape(test_image.size[0],test_image.size[1],4)\n",
    "\n",
    "test_array_trans = test_array[np.newaxis,:,:,:3]\n",
    "test_array_trans = np.einsum('ijkl->ilkj',test_array_trans)\n",
    "\n",
    "cut_value_width = int(rgb_array_trans.shape[3] % 64 /2)\n",
    "cut_value_height = int(rgb_array_trans.shape[2] % 64 /2)\n",
    "\n",
    "test_array_trans = test_array_trans[:,:,cut_value_height:test_array_trans.shape[2] -cut_value_height, \n",
    "                                  cut_value_width:test_array_trans.shape[3] - cut_value_width]\n",
    "\n",
    "number_patches_height = (test_array_trans.shape[2]/64)\n",
    "number_patches_width = (test_array_trans.shape[3]/64)\n",
    "\n",
    "test_batch = np.zeros((int(number_patches_height*number_patches_width),3,64,64))\n",
    "\n",
    "patch_counter = 0\n",
    "\n",
    "for i in range(int(number_patches_height)):\n",
    "    for j in range(int(number_patches_width)):\n",
    "        test_batch[patch_counter,:,:64,:64] = rgb_array_trans[:,:,i*64:(i+1)*64,j*64:(j+1)*64]\n",
    "\n",
    "        patch_counter += 1\n",
    "        \n",
    "        \n",
    "# Predicting the classes using the network. First, we create a prediction_batch to store the patch-predictions\n",
    "\n",
    "y = torch.zeros((test_batch.shape[0],2,64,64))\n",
    "\n",
    "for d in range(test_batch.shape[0]):\n",
    "    x = torch.tensor(rgb_batch[d:d+1,:,:,:], dtype = torch.double)\n",
    "    \n",
    "    y[d,:,:,:] = train.model(x)\n",
    "    \n",
    "    \n",
    "\n",
    "'''\n",
    "Possible further steps: \n",
    "- cross validation to determine the value of certain hyper-parameters like the learning rate or the number of epochs\n",
    "- training on a GPU instead of a CPU\n",
    "- training with a larger data-set\n",
    "- trying some of the augmentations to the Fully Convolutional Network as mentioned in papers based on the one covering\n",
    "    FCCs\n",
    "- higher degree of automization in the image-preprocessing (especially for a possible larger data-set)\n",
    "- visualization of the dense segmentation (mirroring the input image)\n",
    "- \n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
